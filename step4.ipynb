{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70d3d2a2-4525-4e81-a990-e73d2687fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from scipy.stats import kurtosis \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f4fbe4-9fb2-4fb8-8ed7-dfd4738bc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, InterclusterDistance\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Load UCI AIDS crinical dataset - https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175\n",
    "\n",
    "# fetch dataset \n",
    "aids_clinical_trials_group_study_175 = fetch_ucirepo(id=890) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = aids_clinical_trials_group_study_175.data.features \n",
    "y = aids_clinical_trials_group_study_175.data.targets \n",
    "y=y.cid\n",
    "\n",
    "X_raw = X\n",
    "y_raw = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eae8899-0f25-4e78-b561-2b615d42c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train one model\n",
    "def model_train(model, X_train, y_train, X_val, y_val, n_epochs = 100, lr=0.001):\n",
    "#def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=lr)  # modified \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # modified \n",
    " \n",
    "    #n_epochs = 300   # number of epochs to run\n",
    "    #n_epochs = n_epochs   # number of epochs to run # modified\n",
    "    n_epochs = 100   # number of epochs to run # modified\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    " \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b1c00-2abc-45b4-896e-c65506745a2e",
   "metadata": {},
   "source": [
    "## NN + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1887906d-24b1-41e4-ad00-561449617fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1711, 6])\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PCA\n",
    "##\n",
    "\n",
    "num_clusters = 6\n",
    "\n",
    "model = PCA(n_components = num_clusters)\n",
    "X_raw_pca = model.fit_transform(X_raw)\n",
    "\n",
    "X_raw_tensor = torch.tensor(X_raw_pca, dtype=torch.float32)\n",
    "y_raw_tensor = torch.tensor(y_raw, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw_tensor, y_raw_tensor, stratify=y_raw_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80bcb33-5cad-46cf-a8ce-2229d576a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Neural Network + PCA\n",
    "##\n",
    "\n",
    "class Model (nn.Module):\n",
    "    def __init__(self, x):      \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(6, x)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(x, x)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(x, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d10fa7d-489b-426b-bc9c-c4a57ec7eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:  37.52898621300119\n",
      "Cross Validation Score: 0.8585613608360291\n",
      "Test Accuracy: 0.8387850467289719\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores  = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for train, validate in kfold.split(X_train, y_train):\n",
    "    model = Model(36)\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[validate], y_train[validate], 100, 0.001)\n",
    "    cv_scores.append(acc)\n",
    "training_time = time.perf_counter() - start_time\n",
    "print(\"Training Time: \", training_time)\n",
    "\n",
    "acc_mean = np.mean(cv_scores)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    \n",
    "acc_test = metrics.accuracy_score(y_test.numpy(), np.rint(y_pred.numpy()))    \n",
    "\n",
    "print(\"Cross Validation Score: \" + str(acc_mean))\n",
    "print(\"Test Accuracy: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848338b-29cc-4245-a94f-15a1254d6d44",
   "metadata": {},
   "source": [
    "## NN + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3c973aa-a612-4495-b4fc-3ca96d92f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## TruncatedSVD\n",
    "##\n",
    "\n",
    "num_clusters = 6\n",
    "\n",
    "model = TruncatedSVD(n_components=num_clusters)\n",
    "X_raw_truncsvd = model.fit_transform(X_raw)\n",
    "\n",
    "X_raw_tensor = torch.tensor(X_raw_truncsvd, dtype=torch.float32)\n",
    "y_raw_tensor = torch.tensor(y_raw, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw_tensor, y_raw_tensor, stratify=y_raw_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0adfb65-8598-435d-88c8-adb8d5b96d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Neural Network + Randomized Projections\n",
    "##\n",
    "\n",
    "class Model (nn.Module):\n",
    "    def __init__(self, x):      \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(6, x)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(x, x)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(x, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9671c0c7-bf76-4347-a050-e411c85e1eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:  37.9156664070033\n",
      "Cross Validation Score: 0.8392921209335327\n",
      "Test Accuracy: 0.8037383177570093\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores  = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for train, validate in kfold.split(X_train, y_train):\n",
    "    model = Model(36)\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[validate], y_train[validate], 100, 0.001)\n",
    "    cv_scores.append(acc)\n",
    "training_time = time.perf_counter() - start_time\n",
    "print(\"Training Time: \", training_time)\n",
    "\n",
    "acc_mean = np.mean(cv_scores)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    \n",
    "acc_test = metrics.accuracy_score(y_test.numpy(), np.rint(y_pred.numpy()))    \n",
    "\n",
    "print(\"Cross Validation Score: \" + str(acc_mean))\n",
    "print(\"Test Accuracy: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ae989-8ba3-43d2-b3c0-d6a0c795d043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
